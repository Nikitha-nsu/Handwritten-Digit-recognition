{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the NMIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "NR_CLASSES = 10\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = mnist.load_data() #Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23fd66e2470>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot First image\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reshape training data to fit into our model\n",
    "X_train = X_train.reshape(60000,28,28,1) #No.of samples,Img height,Image width,Channels for grayscale\n",
    "X_test = X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the labels categorical variables in a matrix such that\n",
    "##if the output category is digit 5 ..1 will be in 6th position of array\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize pixel values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Re-scaling all pixels to have values between 0 an 1 (Normalize)\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convolution\n",
    "classifier.add(Conv2D(64,kernel_size=3,input_shape=(28,28,1),activation = 'relu'))\n",
    "# 64 is the number of nodes/filters in Convolution layer\n",
    "# Input shape is (Img height, Img width and channels)\n",
    "# kernel size is 3 for filter size of 3x3 filter matrix\n",
    "#Activation function used is Rectifier ReLU for non-linearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nikitha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Max Pooling (reduce Dimensionality and retain spatial variance)\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Second Convolution layer\n",
    "classifier.add(Conv2D(32,kernel_size =3, activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Flatten\n",
    "classifier.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Add Hidden layer (Full Connection)\n",
    "classifier.add(Dense(NR_CLASSES,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling CNN\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # C;assify into categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nikitha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      " - 48s - loss: 1.0128 - accuracy: 0.7255 - val_loss: 0.2899 - val_accuracy: 0.9152\n",
      "Epoch 2/50\n",
      " - 51s - loss: 0.2187 - accuracy: 0.9362 - val_loss: 0.1474 - val_accuracy: 0.9565\n",
      "Epoch 3/50\n",
      " - 59s - loss: 0.1296 - accuracy: 0.9628 - val_loss: 0.0980 - val_accuracy: 0.9707\n",
      "Epoch 4/50\n",
      " - 63s - loss: 0.0953 - accuracy: 0.9721 - val_loss: 0.0718 - val_accuracy: 0.9779\n",
      "Epoch 5/50\n",
      " - 63s - loss: 0.0815 - accuracy: 0.9759 - val_loss: 0.0670 - val_accuracy: 0.9784\n",
      "Epoch 6/50\n",
      " - 61s - loss: 0.0696 - accuracy: 0.9789 - val_loss: 0.0539 - val_accuracy: 0.9836\n",
      "Epoch 7/50\n",
      " - 61s - loss: 0.0629 - accuracy: 0.9808 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
      "Epoch 8/50\n",
      " - 62s - loss: 0.0563 - accuracy: 0.9834 - val_loss: 0.0497 - val_accuracy: 0.9845\n",
      "Epoch 9/50\n",
      " - 61s - loss: 0.0521 - accuracy: 0.9843 - val_loss: 0.0482 - val_accuracy: 0.9836\n",
      "Epoch 10/50\n",
      " - 62s - loss: 0.0507 - accuracy: 0.9844 - val_loss: 0.0478 - val_accuracy: 0.9858\n",
      "Epoch 11/50\n",
      " - 62s - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.0428 - val_accuracy: 0.9862\n",
      "Epoch 12/50\n",
      " - 64s - loss: 0.0434 - accuracy: 0.9869 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
      "Epoch 13/50\n",
      " - 56s - loss: 0.0418 - accuracy: 0.9872 - val_loss: 0.0408 - val_accuracy: 0.9870\n",
      "Epoch 14/50\n",
      " - 50s - loss: 0.0389 - accuracy: 0.9887 - val_loss: 0.0403 - val_accuracy: 0.9873\n",
      "Epoch 15/50\n",
      " - 46s - loss: 0.0372 - accuracy: 0.9888 - val_loss: 0.0378 - val_accuracy: 0.9871\n",
      "Epoch 16/50\n",
      " - 49s - loss: 0.0359 - accuracy: 0.9892 - val_loss: 0.0381 - val_accuracy: 0.9872\n",
      "Epoch 17/50\n",
      " - 49s - loss: 0.0333 - accuracy: 0.9901 - val_loss: 0.0375 - val_accuracy: 0.9883\n",
      "Epoch 18/50\n",
      " - 50s - loss: 0.0335 - accuracy: 0.9895 - val_loss: 0.0378 - val_accuracy: 0.9873\n",
      "Epoch 19/50\n",
      " - 50s - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.0361 - val_accuracy: 0.9876\n",
      "Epoch 20/50\n",
      " - 50s - loss: 0.0305 - accuracy: 0.9911 - val_loss: 0.0371 - val_accuracy: 0.9875\n",
      "Epoch 21/50\n",
      " - 50s - loss: 0.0294 - accuracy: 0.9909 - val_loss: 0.0364 - val_accuracy: 0.9880\n",
      "Epoch 22/50\n",
      " - 50s - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.0382 - val_accuracy: 0.9875\n",
      "Epoch 23/50\n",
      " - 50s - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.0399 - val_accuracy: 0.9882\n",
      "Epoch 24/50\n",
      " - 50s - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.0361 - val_accuracy: 0.9875\n",
      "Epoch 25/50\n",
      " - 50s - loss: 0.0246 - accuracy: 0.9924 - val_loss: 0.0378 - val_accuracy: 0.9884\n",
      "Epoch 26/50\n",
      " - 50s - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.0372 - val_accuracy: 0.9873\n",
      "Epoch 27/50\n",
      " - 50s - loss: 0.0225 - accuracy: 0.9933 - val_loss: 0.0364 - val_accuracy: 0.9891\n",
      "Epoch 28/50\n",
      " - 50s - loss: 0.0221 - accuracy: 0.9931 - val_loss: 0.0391 - val_accuracy: 0.9863\n",
      "Epoch 29/50\n",
      " - 50s - loss: 0.0219 - accuracy: 0.9932 - val_loss: 0.0395 - val_accuracy: 0.9876\n",
      "Epoch 30/50\n",
      " - 50s - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0352 - val_accuracy: 0.9894\n",
      "Epoch 31/50\n",
      " - 50s - loss: 0.0193 - accuracy: 0.9941 - val_loss: 0.0342 - val_accuracy: 0.9895\n",
      "Epoch 32/50\n",
      " - 49s - loss: 0.0188 - accuracy: 0.9943 - val_loss: 0.0354 - val_accuracy: 0.9899\n",
      "Epoch 33/50\n",
      " - 50s - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0370 - val_accuracy: 0.9886\n",
      "Epoch 34/50\n",
      " - 49s - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0346 - val_accuracy: 0.9894\n",
      "Epoch 35/50\n",
      " - 45s - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.0368 - val_accuracy: 0.9883\n",
      "Epoch 36/50\n",
      " - 49s - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0353 - val_accuracy: 0.9892\n",
      "Epoch 37/50\n",
      " - 50s - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0364 - val_accuracy: 0.9899\n",
      "Epoch 38/50\n",
      " - 50s - loss: 0.0142 - accuracy: 0.9957 - val_loss: 0.0387 - val_accuracy: 0.9885\n",
      "Epoch 39/50\n",
      " - 50s - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.0354 - val_accuracy: 0.9898\n",
      "Epoch 40/50\n",
      " - 48s - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.0358 - val_accuracy: 0.9896\n",
      "Epoch 41/50\n",
      " - 50s - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0383 - val_accuracy: 0.9893\n",
      "Epoch 42/50\n",
      " - 56s - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0377 - val_accuracy: 0.9881\n",
      "Epoch 43/50\n",
      " - 60s - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0381 - val_accuracy: 0.9897\n",
      "Epoch 44/50\n",
      " - 68s - loss: 0.0108 - accuracy: 0.9971 - val_loss: 0.0391 - val_accuracy: 0.9887\n",
      "Epoch 45/50\n",
      " - 64s - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0417 - val_accuracy: 0.9895\n",
      "Epoch 46/50\n",
      " - 62s - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0399 - val_accuracy: 0.9896\n",
      "Epoch 47/50\n",
      " - 64s - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.0398 - val_accuracy: 0.9894\n",
      "Epoch 48/50\n",
      " - 65s - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0399 - val_accuracy: 0.9891\n",
      "Epoch 49/50\n",
      " - 64s - loss: 0.0087 - accuracy: 0.9980 - val_loss: 0.0452 - val_accuracy: 0.9877\n",
      "Epoch 50/50\n",
      " - 62s - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0410 - val_accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23fd2cadb70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit CNN model\n",
    "classifier.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=1000, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prection and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.60204379e-12, 7.48092477e-10, 3.80004028e-09, 2.30409380e-09,\n",
       "        7.21797178e-15, 3.67386853e-14, 2.50645209e-24, 1.00000000e+00,\n",
       "        1.54909852e-12, 1.04487112e-08],\n",
       "       [6.66703637e-10, 3.11344071e-12, 1.00000000e+00, 2.86803757e-13,\n",
       "        3.28259823e-18, 1.96243327e-18, 5.59632118e-10, 5.16877292e-15,\n",
       "        1.11687426e-09, 1.33826454e-16],\n",
       "       [7.14769355e-10, 9.99971271e-01, 5.70232771e-07, 4.00849881e-10,\n",
       "        1.73934222e-05, 2.13259699e-09, 1.24654065e-09, 3.60595868e-06,\n",
       "        7.19745049e-06, 1.70301426e-08],\n",
       "       [9.99990106e-01, 1.83420366e-16, 4.84665502e-11, 2.33581236e-15,\n",
       "        1.13301685e-14, 6.14155211e-13, 9.84750841e-06, 5.42950788e-11,\n",
       "        3.59477587e-11, 5.90096071e-12]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = classifier.predict((X_test[:4]))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction by model  for first 4 images are [7 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Print predictions\n",
    "classes = np.argmax(prediction,axis=1)\n",
    "print('The prediction by model  for first 4 images are', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Verify the actual images\n",
    "verify_img = y_test[:4]\n",
    "verify_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digits to test first 4 are 7,2,1,0\n"
     ]
    }
   ],
   "source": [
    "print('The digits to test first 4 are 7,2,1,0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04100977505862575, 0.9889000058174133]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = classifier.evaluate(X_test,y_test,verbose=0)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAhmVYSWZNTQAqAAAACAACARIAAwAAAAEAAQAAh2kABAAAAAEAAAAmAAAAAAAEkAMAAgAAABQAAABckAQAAgAAABQAAABwkpEAAgAAAAMwMAAAkpIAAgAAAAMwMAAAAAAAADIwMjA6MDU6MDQgMTk6NTI6MzAAMjAyMDowNTowNCAxOTo1MjozMAAAAFh2FTQAAAPgSURBVHicdVZLS+tAFD7zSPpIe6ulthBUhC66K4Iu1IV/xf/pwr0oCKLirhQVlVZFi00yz7v4esdYvWcRmGTmO4/vO2fCvPd5nlerVSLSWkdRhKdzjnNORETkvceSMUZEWZZFUSSlJCJrLRExxsJmImLOOWutlNI5R0Sc8wBnrXXORVGErdbaoijq9XpYGmOiKCrDLUCVUjiGAINzIUQ4bK0VQuCNUiqOYyIyxgghEPuS8XA4mHNOCDGfz7EUQsRx7L3XWmutgWitDdXQWiPLr0i99+VNZf+z2ezl5SXLsmq12mw2pZTGmFarhYRCuX5Gyrz33ntUB1s555+fn8fHx61Wa3V1tdFoVCoVa+3b29vr62u32+31er1ej4iKoqhUKoipnDEDs845KWX4dnZ2JqVM0xSHIQDsvLq6yvN8c3MzTVPvPXIK+lnUFIIAltYaVNze3vb7/bW1NcSO95xzKeX29rZSajweO+cYY0opIkKhv0CNMYwxMB5kMBqN/vz5A3kRESQJ8VlrDw8PT09POecgAGF9Ay1rGJYkycHBgXPOe885B4GQtxACzOzu7nrvcVYptQxaXgghiqIgov39fYCWv6KsWuuiKGq1Wuiln6LkOBlcYWuSJIgRL5E43ERRFMfxeDyG/hB+OdFfQOM4DrSEAENEKEWWZVAS0iciY0wZdCF+Y4y1FlvLbpZcElGWZaPRqNlsttvtJEnot35duJJSMsbKoygUMYRsjNFaPzw8GGPSNEXKEPgvNUXwwVvgp+zcOTefz9/f37XWW1tb3vs4jsEqEeV5/i19KDFMCnSeMQadHsidTqeTyWQ+nw+HQ5BD/zdeFAVjDIhhkuJMKP90Oh2Px1LKnZ0dDNAghtC+vxCltbbWon+DHiuVClrWGNPv91utVhgOPwlcBnXOKaWAiI7G7slkcn9/H0VRmqbtdpt+TKP/mbTWKqVqtRoRKaUwNYhoNps9Pj4yxvr9fq1WK4rCWluv17XWkAr9u7vYP/sCFUIABXMM/Dw/P9/d3a2vr3e7XYwVSDiM3UWa37G+QIkoiiJjjFKqXq8rpW5ubjjnvV4vSZJwNVFJalAhIvh18vMsy4hISokKXF5enp+fNxqNjY2NVqslhAhDRGuNfp/NZm9vbx8fH0GnS6OHYUQiqZOTk+vr6729vZWVlVA4DOk8z/M811pPJpOnp6eLi4tOp3N0dDQYDDBWyiFLrPGh0+kMh8PBYIB/BczQwAkMBGRZZq1tNBr4tFSExfWJ53w+9943Go3y78mSlS87zrnW2hhTrVa//aFAIuV7nEoXWWibQDd4s9Yu/eqU7S/Cnecu9f2k/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=28x28 at 0x23FD44F02E8>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Testing a new Image\n",
    "img = Image.open('D:/Data/Downloads/2.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAhmVYSWZNTQAqAAAACAACARIAAwAAAAEAAQAAh2kABAAAAAEAAAAmAAAAAAAEkAMAAgAAABQAAABckAQAAgAAABQAAABwkpEAAgAAAAMwMAAAkpIAAgAAAAMwMAAAAAAAADIwMjA6MDU6MDQgMTk6NTI6MzAAMjAyMDowNTowNCAxOTo1MjozMAAAAFh2FTQAAAHiSURBVHicRZJBa1NREIW/mXvvS9K0RkttIKgIXXRXBF2oC/+K/9OFe1EQRKW7UlRUWhUtJnnv3plxkRRne4ZzZs45EusxtdTiCuEqrErGEAXELTvqinkB63fAWlEAZCjUgpHALCWGjpYEADQB4GkJqYtaO0yF6gASmEpLwtWP1Xgvt1nB2bAiEa3g+vfF7NbuyH79PJzP6UdYAiTcsyVe58UcIvz9+t4ihPUYUCRRGU6PbuMVzQ+Gc5eBDkCbGIV6dkOdjJs9e6UtIQCaMWD61ENVRJPyKDLDBgRIPU88ACJqPzFk86AGAsZUFdw8SncuTZP9B7uKQiBJZTUiQ9ua0GxEIAQCrM729qdbBzNkcRWIUGj1S1sYnreajSQECODL3/V+dD2sAcSpHf2o5SaJy4vlyTYKAO2lw5VEg8vz/LCoeURcp1JtTEQdDaftaGZpe9gG9GGMi3DxuSz2N2lcT7ZhwqCZq69yNOltp2YhXESAnDIhuX3/dOdQfUQrgGx5M6UNO8NHnU9TgoBokrdN0BV5wrs3u3dnKWpfpV39+tNDAIhZ4eWHxzez4HW9rhff3h48P26qQFZtenByXLKoEBGZle0SCiAttbSMXd/K0I8wrW2sgNRsKrAe4xEgCZPrxX/YfffU+EwKawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x23FD44F02B0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw = img.convert('L') #Convert color image to grey scale image\n",
    "bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = np.invert(bw) #Covert bw image to ndarray\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = img_array.reshape(1,28,28,1)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = classifier.predict(img_array)\n",
    "np.argmax(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
